model:
  encoder:
    class_path: mini_mask_git.modules.TransformerSequenceEncoder
    init_args:
      embed_dim: 256
      dim_model: 256
      num_layers: 6
      nhead: 4
      dim_feedforward: 512
      activation: gelu
      max_len: 1024
      dropout: 0.0
